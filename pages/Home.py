# pages/Home.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import timedelta, date, datetime
import time

import config
from utils import (
    download_data, create_features, train_models_pipeline,
    generate_predictions_pipeline, add_market_data_features,
    generate_iterative_forecast,
    parse_int_list,
    add_fundamental_features
)

st.set_page_config(page_title="Monarch: Stock Price Predictor", layout="wide")

st.header("ðŸ“ˆ Single Stock Analysis & Predictor")
st.markdown("Analyze a single stock in-depth, visualize its historical data with technical indicators, and forecast future prices using machine learning.")

# --- Sidebar ---
st.sidebar.header("ðŸ› ï¸ Configuration Panel")
ticker = st.sidebar.text_input("Enter Stock Ticker:", value="AAPL").upper()

# --- Date Inputs ---
st.sidebar.subheader("ðŸ—“ï¸ Training Period")
today = date.today()
default_end_bt = today - timedelta(days=1)
default_start_bt = default_end_bt - timedelta(days=5*365)
start_bt = st.sidebar.date_input("Training Start Date (t1):", value=default_start_bt)
end_bt = st.sidebar.date_input("Training End Date (t2):", value=default_end_bt)

if start_bt >= end_bt:
    st.sidebar.error("Start Date must be before End Date.")
    st.stop()

# --- Feature Selection ---
st.sidebar.subheader("âž• Add Features")
# Global Context Selector
with st.sidebar.expander("ðŸŒ Global Context Features"):
    available_indices = list(config.GLOBAL_MARKET_TICKERS.keys())
    select_all_globals = st.checkbox("Select All Global Indices", value=False, key="home_select_all_globals")
    default_globals = available_indices if select_all_globals else available_indices[:3]
    selected_indices = st.multiselect("Select Global Indices:", options=available_indices, default=default_globals)
    selected_tickers = [config.GLOBAL_MARKET_TICKERS[name] for name in selected_indices]

# Fundamental Features Selector
with st.sidebar.expander("ðŸ”¬ Fundamental Features"):
    # Existing static fundamentals
    available_fundamentals_static = list(config.FUNDAMENTAL_METRICS.keys())
    select_all_fundamentals_static = st.checkbox("Select All Static Fundamentals", value=False, key="home_select_all_fundamentals_static")
    default_fundamentals_static = available_fundamentals_static if select_all_fundamentals_static else []
    selected_fundamental_names_static = st.multiselect("Select Static Fundamental Metrics:", options=available_fundamentals_static, default=default_fundamentals_static, key="home_static_fundamental_select")
    selected_fundamentals_static = {name: config.FUNDAMENTAL_METRICS[name] for name in selected_fundamental_names_static}

    # New: Historical/Derived Fundamentals
    # These are the column names that will be generated by add_fundamental_features
    available_fundamentals_derived = ['Historical P/E Ratio', 'Historical P/S Ratio', 'Historical Debt to Equity']
    select_all_fundamentals_derived = st.checkbox("Select All Historical/Derived Fundamentals", value=False, key="home_select_all_fundamentals_derived")
    default_fundamentals_derived = available_fundamentals_derived if select_all_fundamentals_derived else []
    selected_fundamental_names_derived = st.multiselect("Select Historical/Derived Metrics:", options=available_fundamentals_derived, default=default_fundamentals_derived, key="home_derived_fundamental_select")
    # For derived fundamentals, the key and value are the same (the column name)
    selected_fundamentals_derived = {name: name for name in selected_fundamental_names_derived}

# Combine selected fundamentals for passing to the utility function
# The `add_fundamental_features` function will intelligently use the `yf_key` for static and the `name` for derived.
combined_selected_fundamentals = {**selected_fundamentals_static, **selected_fundamentals_derived}


# --- Model Selection ---
st.sidebar.subheader("ðŸ¤– Model Selection")
model_choice = st.sidebar.selectbox("Select Main Model:", config.MODEL_CHOICES)
perform_tuning = st.sidebar.checkbox("Perform Hyperparameter Tuning", value=False, help="Optimizes model parameters. May significantly increase training time.")
n_future = st.sidebar.slider("Predict Future Days:", 1, 90, config.DEFAULT_N_FUTURE_DAYS)

# --- Model Comparison ---
st.sidebar.subheader("ðŸ“Š Model Comparison")
available_models_for_comparison = [m for m in config.MODEL_CHOICES if m != 'Prophet']
select_all_models = st.sidebar.checkbox("Select All Models for Comparison", value=False, key="home_select_all_models")
default_compare_models = available_models_for_comparison if select_all_models else [m for m in config.MODEL_CHOICES if m not in ['Prophet', 'KNN']][:3]
compare_models = st.sidebar.multiselect("Select Models to Compare:", options=available_models_for_comparison, default=default_compare_models)
train_days_comparison = st.sidebar.slider("Recent Data for Comparison (days):", 30, 1000, config.DEFAULT_RECENT_DATA_FOR_COMPARISON, 10)

# --- Technical Indicator Settings ---
st.sidebar.subheader("âš™ï¸ Technical Indicator Settings")
selected_indicator_params = {}
with st.sidebar.expander("Show Indicator Settings"):
    for indicator_name, (default_value, default_enabled) in config.TECHNICAL_INDICATORS_DEFAULTS.items():
        if st.checkbox(f"Enable {indicator_name.replace('_', ' ')}", value=default_enabled, key=f"enable_{indicator_name.lower()}_home"):
            if isinstance(default_value, list):
                selected_indicator_params[indicator_name] = parse_int_list(st.text_input(f"  {indicator_name.replace('_', ' ')} (days):", ", ".join(map(str, default_value)), key=f"input_{indicator_name.lower()}_home"), default_value, st.sidebar.error)
            elif isinstance(default_value, (int, float)):
                min_val, step_val = (0.01, 0.01) if 'ACCEL' in indicator_name or isinstance(default_value, float) else (1.0, 1.0)
                selected_indicator_params[indicator_name] = st.number_input(f"  {indicator_name.replace('_', ' ')}:", min_value=min_val, value=float(default_value), step=step_val, key=f"input_{indicator_name.lower()}_home")

# --- Logging Setup ---
if 'training_log' not in st.session_state: st.session_state.training_log = []
def clear_log(): st.session_state.training_log = []
def update_log(message): st.session_state.training_log.insert(0, f"[{datetime.now().strftime('%H:%M:%S')}] {message}")
with st.sidebar.expander("ðŸ“œ Training Log", expanded=True):
    st.code("\n".join(st.session_state.training_log), language=None)

# --- Main Application Flow ---
if st.button("Run Analysis", type="primary", on_click=clear_log):
    update_log(f"Starting analysis for {ticker}...")
    data = download_data(ticker)
    if data.empty:
        st.error(f"Could not load data for {ticker}. Please check the ticker symbol."); st.stop()
    update_log(f"Data loaded: {len(data)} rows.")
    
    with st.spinner("Processing data and creating features..."):
        data_for_features = data.copy()
        # Pass the combined selected fundamentals
        if combined_selected_fundamentals: data_for_features = add_fundamental_features(data_for_features, ticker, combined_selected_fundamentals, _update_log_func=update_log)
        if selected_tickers: data_for_features = add_market_data_features(data_for_features, "10y", update_log, selected_tickers=selected_tickers)
        df_features_full = create_features(data_for_features, selected_indicator_params)
        update_log(f"Features created. Rows after NaN drop: {len(df_features_full)}")
        df_train_period = df_features_full[(df_features_full['Date'] >= pd.to_datetime(start_bt)) & (df_features_full['Date'] <= pd.to_datetime(end_bt))].copy()
        if df_train_period.empty:
            st.error("No data in selected training range. Please adjust the dates."); st.stop()
        update_log(f"Training data prepared: {len(df_train_period)} rows.")

    # --- Model Training and Prediction Loop ---
    all_trained_models, all_future_forecasts, all_historical_predictions, model_performance_data = {}, {}, {}, []
    models_to_run = sorted(list(set([model_choice] + compare_models)))

    for model_name in models_to_run:
        with st.spinner(f"Processing {model_name}..."):
            update_log(f"Training {model_name}...")
            trained_models, _ = train_models_pipeline(df_train_period.copy(), model_name, (model_name == model_choice and perform_tuning), update_log, selected_indicator_params)
            if not trained_models:
                update_log(f"âœ— Failed to train {model_name}."); continue
            
            all_trained_models[model_name] = trained_models
            update_log(f"âœ“ {model_name} trained successfully.")

            # Generate future forecasts (iterative method)
            if model_name != 'Prophet':
                update_log(f"Generating {n_future}-day forecast with {model_name}...")
                future_df = generate_iterative_forecast(data, trained_models, ticker, n_future, end_bt, selected_indicator_params, update_log, selected_tickers, combined_selected_fundamentals)
                if not future_df.empty:
                    all_future_forecasts[model_name] = future_df
                    update_log(f"âœ“ Forecast generated for {model_name}.")
                
                # Generate historical predictions for performance comparison
                df_comparison_period = df_features_full[(df_features_full['Date'] >= pd.to_datetime(end_bt) - timedelta(days=train_days_comparison)) & (df_features_full['Date'] <= pd.to_datetime(end_bt))]
                if len(df_comparison_period) > 1:
                    preds_dict = generate_predictions_pipeline(df_comparison_period.copy(), trained_models, (lambda x: None))
                    if 'Close' in preds_dict and not preds_dict['Close'].empty:
                        merged_df = pd.merge(df_comparison_period[['Date', 'Close']], preds_dict['Close'], on='Date', how='inner')
                        all_historical_predictions[model_name] = merged_df
                        mae = np.mean(np.abs(merged_df['Close'] - merged_df['Predicted Close']))
                        rmse = np.sqrt(np.mean((merged_df['Close'] - merged_df['Predicted Close'])**2))
                        model_performance_data.append({'Model': model_name, 'MAE': mae, 'RMSE': rmse})

    # --- Section 1: Main Candlestick Chart with Forecasts ---
    st.subheader(f"Candlestick Chart & Forecasts for {ticker}")
    st.markdown("This chart displays the recent historical price action and overlays the future price forecasts generated by the selected models.")
    fig = go.Figure()
    fig.add_trace(go.Candlestick(x=df_features_full['Date'].tail(180), open=df_features_full['Open'].tail(180), high=df_features_full['High'].tail(180), low=df_features_full['Low'].tail(180), close=df_features_full['Close'].tail(180), name='Historical Price'))
    for model_name, forecast_df in all_future_forecasts.items():
        fig.add_trace(go.Scatter(x=forecast_df['Date'], y=forecast_df['Close'], mode='lines+markers', name=f'Forecast ({model_name})'))
    fig.update_layout(xaxis_rangeslider_visible=False, title=f'{ticker} Price Prediction', yaxis_title='Price', height=600, template='plotly_white', legend_title="Legend")
    st.plotly_chart(fig, use_container_width=True)
    
    # --- Section 2: Future Prices Data Table ---
    if all_future_forecasts:
        st.subheader("Consolidated Future Price Forecasts")
        st.markdown("The table below shows the predicted closing prices for the upcoming days from each model.")
        final_forecast_table = None
        for model_name, forecast_df in all_future_forecasts.items():
            forecast_subset = forecast_df[['Date', 'Close']].rename(columns={'Close': model_name})
            final_forecast_table = forecast_subset if final_forecast_table is None else pd.merge(final_forecast_table, forecast_subset, on='Date', how='outer')
        if final_forecast_table is not None:
            st.dataframe(final_forecast_table.set_index('Date').style.format("{:.2f}"), use_container_width=True)
    else:
        st.warning("Could not generate future forecasts. This may happen if the selected models are not suitable for iterative forecasting (e.g., Prophet).")

    # --- Section 3: Historical Performance Comparison ---
    if all_historical_predictions:
        st.subheader(f"Historical Model Performance ({train_days_comparison} days)")
        st.markdown("This chart compares the models' past predictions against the actual stock price to evaluate their historical accuracy.")
        comparison_fig = go.Figure()
        df_comparison_period = df_features_full[(df_features_full['Date'] >= pd.to_datetime(end_bt) - timedelta(days=train_days_comparison)) & (df_features_full['Date'] <= pd.to_datetime(end_bt))]
        comparison_fig.add_trace(go.Scatter(x=df_comparison_period['Date'], y=df_comparison_period['Close'], mode='lines', name='Actual Price', line=dict(color='black', width=3)))
        for model_name, merged_df in all_historical_predictions.items():
            comparison_fig.add_trace(go.Scatter(x=merged_df['Date'], y=merged_df['Predicted Close'], mode='lines', name=f'{model_name} Prediction', line=dict(dash='dot')))
        comparison_fig.update_layout(title="Model Comparison on Historical Data", yaxis_title="Price", height=500, template='plotly_white')
        st.plotly_chart(comparison_fig, use_container_width=True)
        
        st.subheader("Model Performance Metrics (on Recent Data)")
        st.markdown("Lower MAE and RMSE values indicate better performance.")
        st.dataframe(pd.DataFrame(model_performance_data).sort_values(by='MAE').style.format({'MAE': '{:.4f}', 'RMSE': '{:.4f}'}), use_container_width=True)
    else:
        st.warning("Could not generate historical performance data. Ensure you have selected models for comparison.")

    # --- Section 4: Technical Indicator Graphs ---
    st.subheader("Supplementary Technical Indicator Charts")
    df_plot_period = df_features_full.tail(365)
    if 'RSI' in df_plot_period.columns:
        fig_rsi = go.Figure()
        fig_rsi.add_trace(go.Scatter(x=df_plot_period['Date'], y=df_plot_period['RSI'], mode='lines', name='RSI'))
        fig_rsi.add_hline(y=70, line_dash="dash", line_color="red", annotation_text="Overbought")
        fig_rsi.add_hline(y=30, line_dash="dash", line_color="green", annotation_text="Oversold")
        fig_rsi.update_layout(title='Relative Strength Index (RSI)', yaxis_title='RSI', height=300)
        st.plotly_chart(fig_rsi, use_container_width=True)
    if 'MACD' in df_plot_period.columns and 'MACD_Signal' in df_plot_period.columns:
        fig_macd = go.Figure()
        fig_macd.add_trace(go.Scatter(x=df_plot_period['Date'], y=df_plot_period['MACD'], name='MACD', line_color='blue'))
        fig_macd.add_trace(go.Scatter(x=df_plot_period['Date'], y=df_plot_period['MACD_Signal'], name='Signal', line_color='orange'))
        fig_macd.update_layout(title='MACD', yaxis_title='Value', height=300)
        st.plotly_chart(fig_macd, use_container_width=True)

    # --- Section 5: Feature Importance and Analysis ---
    st.subheader("Feature Importance Analysis")
    st.markdown(f"This section reveals which data points (features) the main model **({model_choice})** considered most important when making its predictions.")
    col1, col2 = st.columns([2, 1])
    with col1:
        main_model_info = all_trained_models.get(model_choice, {}).get('Close')
        if main_model_info and hasattr(main_model_info['model'], 'feature_importances_'):
            imp_df = pd.DataFrame({'Feature': main_model_info['features'], 'Importance': main_model_info['model'].feature_importances_}).sort_values(by='Importance', ascending=False).head(20)
            fig_imp = px.bar(imp_df, x='Importance', y='Feature', orientation='h', title=f"Top 20 Features for {model_choice}")
            fig_imp.update_layout(yaxis={'categoryorder':'total ascending'})
            st.plotly_chart(fig_imp, use_container_width=True)
        else:
            st.info(f"Feature importance not available for the '{model_choice}' model type.")

    with col2:
        st.markdown("##### Feature Type Insights")
        if 'imp_df' in locals():
            fundamental_feature_keys = [name.replace(' ', '_') for name in config.FUNDAMENTAL_METRICS.keys()]
            # Add the new historical fundamental feature keys
            historical_fundamental_keys = ['Historical_PE_Ratio', 'Historical_PS_Ratio', 'Historical_Debt_to_Equity']
            all_fundamental_keys = fundamental_feature_keys + historical_fundamental_keys

            fundamental_features_found = [feat for feat in imp_df['Feature'] if feat in all_fundamental_keys]
            if fundamental_features_found:
                st.success("ðŸ”¬ Fundamental features were influential!")
                for feature in fundamental_features_found: st.markdown(f"- **{feature}**")
            
            expected_global_substrings = [name.replace(' ', '_').replace('^', '') for name in selected_indices]
            global_features_found = [col for col in imp_df['Feature'] if any(sub in col for sub in expected_global_substrings)]
            if global_features_found:
                st.success("ðŸŒ Global context features were influential!")
                for feature in global_features_found: st.markdown(f"- **{feature}**")

            if not fundamental_features_found and not global_features_found:
                st.info("The top features were primarily technical indicators derived from the stock's own price history.")
        else:
            st.info("Run analysis to see feature type insights.")

